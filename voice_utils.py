# voice_utils.py
# ìŒì„± ì¸ì‹ (STT) ë° ìŒì„± í‰ê°€ ìœ í‹¸ë¦¬í‹°
# ë„¤ì´ë²„ í´ë¡œë°” ë”ë¹™ + OpenAI TTS ì§€ì›

import os
import re
import json
import tempfile
import requests
from typing import Optional, Dict, Any, List, Tuple
from io import BytesIO

# OpenAI API ì„¤ì •
OPENAI_API_URL = "https://api.openai.com/v1"

# ë„¤ì´ë²„ í´ë¡œë°” ë³´ì´ìŠ¤ API ì„¤ì •
CLOVA_VOICE_URL = "https://naveropenapi.apigw.ntruss.com/tts-premium/v1/tts"

# =====================
# ë„¤ì´ë²„ í´ë¡œë°” ë³´ì´ìŠ¤ ìŠ¤í”¼ì»¤ ëª©ë¡
# =====================
# í•œêµ­ì–´ Premium ìŒì„± (ê°ì • ì§€ì›)
CLOVA_SPEAKERS = {
    # ì—¬ì„± ìŒì„±
    "nara": {"name": "ë‚˜ë¼", "gender": "female", "age": "young", "emotion": True, "desc": "20ëŒ€ ì—¬ì„±, ì°¨ë¶„í•¨"},
    "nara_call": {"name": "ë‚˜ë¼(ìƒë‹´ì›)", "gender": "female", "age": "young", "emotion": False, "desc": "ìƒë‹´ì› í†¤"},
    "nminsang": {"name": "ë¯¼ìƒ", "gender": "female", "age": "young", "emotion": True, "desc": "20ëŒ€ ì—¬ì„±, ë°ìŒ"},
    "nyejin": {"name": "ì˜ˆì§„", "gender": "female", "age": "young", "emotion": True, "desc": "20ëŒ€ ì—¬ì„±, í™œë°œí•¨"},
    "mijin": {"name": "ë¯¸ì§„", "gender": "female", "age": "adult", "emotion": False, "desc": "ì„±ì¸ ì—¬ì„±"},
    "jinho": {"name": "ì§„í˜¸(ì—¬)", "gender": "female", "age": "adult", "emotion": False, "desc": "ì„±ì¸ ì—¬ì„±"},
    "nsunhee": {"name": "ì„ í¬", "gender": "female", "age": "middle", "emotion": True, "desc": "40-50ëŒ€ ì—¬ì„±"},
    "nsunkyung": {"name": "ì„ ê²½", "gender": "female", "age": "middle", "emotion": True, "desc": "40-50ëŒ€ ì—¬ì„±, ë”°ëœ»í•¨"},
    "nyoungmi": {"name": "ì˜ë¯¸", "gender": "female", "age": "senior", "emotion": True, "desc": "60ëŒ€ ì´ìƒ ì—¬ì„±"},

    # ë‚¨ì„± ìŒì„±
    "njonghyun": {"name": "ì¢…í˜„", "gender": "male", "age": "young", "emotion": True, "desc": "20ëŒ€ ë‚¨ì„±"},
    "njoonyoung": {"name": "ì¤€ì˜", "gender": "male", "age": "young", "emotion": True, "desc": "20ëŒ€ ë‚¨ì„±, ë°ìŒ"},
    "nwontak": {"name": "ì›íƒ", "gender": "male", "age": "adult", "emotion": True, "desc": "30ëŒ€ ë‚¨ì„±"},
    "nsangdo": {"name": "ìƒë„", "gender": "male", "age": "middle", "emotion": True, "desc": "40-50ëŒ€ ë‚¨ì„±"},
    "nseungpyo": {"name": "ìŠ¹í‘œ", "gender": "male", "age": "middle", "emotion": True, "desc": "40-50ëŒ€ ë‚¨ì„±, ê¶Œìœ„"},
    "nkyungtae": {"name": "ê²½íƒœ", "gender": "male", "age": "senior", "emotion": True, "desc": "60ëŒ€ ì´ìƒ ë‚¨ì„±"},

    # ì•„ì´/ìºë¦­í„° ìŒì„±
    "ndain": {"name": "ë‹¤ì¸", "gender": "female", "age": "child", "emotion": True, "desc": "ì–´ë¦°ì´ ì—¬ì•„"},
    "nmeow": {"name": "ì•¼ì˜¹ì´", "gender": "female", "age": "child", "emotion": False, "desc": "ê·€ì—¬ìš´ ìºë¦­í„°"},
}

# ê°ì • ì½”ë“œ
CLOVA_EMOTIONS = {
    "neutral": 0,   # ê¸°ë³¸
    "happy": 1,     # ê¸°ì¨
    "sad": 2,       # ìŠ¬í””
    "angry": 3,     # í™”ë‚¨
}


def get_clova_api_keys() -> Tuple[str, str]:
    """ë„¤ì´ë²„ í´ë¡œë°” API í‚¤ ê°€ì ¸ì˜¤ê¸°"""
    client_id = os.environ.get("CLOVA_CLIENT_ID", "") or os.environ.get("NCP_CLIENT_ID", "")
    client_secret = os.environ.get("CLOVA_CLIENT_SECRET", "") or os.environ.get("NCP_CLIENT_SECRET", "")
    return client_id, client_secret


def is_clova_available() -> bool:
    """í´ë¡œë°” API ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
    client_id, client_secret = get_clova_api_keys()
    return bool(client_id and client_secret)


def get_clova_speaker_for_persona(persona: str, escalation_level: int = 0) -> Tuple[str, str, int]:
    """
    í˜ë¥´ì†Œë‚˜ì— ë§ëŠ” í´ë¡œë°” ìŠ¤í”¼ì»¤ ì„ íƒ

    Args:
        persona: ìŠ¹ê° í˜ë¥´ì†Œë‚˜ ë¬¸ìì—´
        escalation_level: ê°ì • ë ˆë²¨ (0: í‰ìƒì‹œ, 1: ì§œì¦, 2: í™”ë‚¨)

    Returns:
        (speaker_id, speed, emotion_code) íŠœí”Œ
    """
    # ê°ì • ë§¤í•‘
    emotion_map = {0: "neutral", 1: "neutral", 2: "angry"}
    emotion = emotion_map.get(escalation_level, "neutral")
    emotion_code = CLOVA_EMOTIONS.get(emotion, 0)

    # ì†ë„ ì„¤ì • (í™”ë‚ ìˆ˜ë¡ ë¹ ë¥´ê²Œ)
    speed_map = {0: 0, 1: 1, 2: 2}  # -5 ~ 5 ë²”ìœ„, 0ì´ ê¸°ë³¸
    speed = speed_map.get(escalation_level, 0)

    # ì„±ë³„ íŒë‹¨
    is_female = any(kw in persona for kw in ['ì—¬ì„±', 'ì—„ë§ˆ', 'í• ë¨¸ë‹ˆ', 'ì—¬ì', 'ë¶€ì¸', 'ì„ì‚°ë¶€', 'ì•„ì¤Œë§ˆ'])
    is_male = any(kw in persona for kw in ['ë‚¨ì„±', 'ì•„ë¹ ', 'í• ì•„ë²„ì§€', 'ë‚¨ì', 'ì‚¬ì—…ê°€']) and not is_female

    # ë‚˜ì´ëŒ€ íŒë‹¨
    if any(kw in persona for kw in ['60ëŒ€', '70ëŒ€', 'ì–´ë¥´ì‹ ', 'í• ë¨¸ë‹ˆ', 'í• ì•„ë²„ì§€', 'ë…¸ì¸']):
        age = "senior"
    elif any(kw in persona for kw in ['50ëŒ€', '40ëŒ€']):
        age = "middle"
    elif any(kw in persona for kw in ['30ëŒ€', 'ì§ì¥ì¸']):
        age = "adult"
    elif any(kw in persona for kw in ['20ëŒ€', 'ëŒ€í•™ìƒ', 'ì Šì€']):
        age = "young"
    elif any(kw in persona for kw in ['ì–´ë¦°ì´', 'ì•„ë™', 'ì•„ì´']):
        age = "child"
    else:
        age = "adult"

    # ìŠ¤í”¼ì»¤ ì„ íƒ
    if age == "child":
        speaker = "ndain"
    elif is_female:
        if age == "senior":
            speaker = "nyoungmi"  # 60ëŒ€ ì´ìƒ ì—¬ì„±
        elif age == "middle":
            speaker = "nsunhee"  # 40-50ëŒ€ ì—¬ì„±
        elif age == "young":
            speaker = "nyejin"  # 20ëŒ€ ì—¬ì„±
        else:
            speaker = "nara"  # ê¸°ë³¸ ì—¬ì„±
    else:  # ë‚¨ì„± ë˜ëŠ” ê¸°ë³¸
        if age == "senior":
            speaker = "nkyungtae"  # 60ëŒ€ ì´ìƒ ë‚¨ì„±
        elif age == "middle":
            speaker = "nsangdo"  # 40-50ëŒ€ ë‚¨ì„±
        elif age == "young":
            speaker = "njonghyun"  # 20ëŒ€ ë‚¨ì„±
        else:
            speaker = "nwontak"  # 30ëŒ€ ë‚¨ì„±

    return (speaker, speed, emotion_code)


def generate_clova_tts(
    text: str,
    speaker: str = "nara",
    speed: int = 0,
    emotion: int = 0,
    volume: int = 0,
    pitch: int = 0,
) -> Optional[bytes]:
    """
    ë„¤ì´ë²„ í´ë¡œë°” ë³´ì´ìŠ¤ APIë¡œ TTS ìƒì„±

    Args:
        text: ë³€í™˜í•  í…ìŠ¤íŠ¸ (ìµœëŒ€ 2000ì)
        speaker: ìŠ¤í”¼ì»¤ ID
        speed: ì†ë„ (-5 ~ 5, ê¸°ë³¸ 0)
        emotion: ê°ì • (0: ê¸°ë³¸, 1: ìŠ¬í””, 2: ê¸°ì¨, 3: í™”ë‚¨)
        volume: ë³¼ë¥¨ (-5 ~ 5, ê¸°ë³¸ 0)
        pitch: í”¼ì¹˜ (-5 ~ 5, ê¸°ë³¸ 0)

    Returns:
        MP3 ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë˜ëŠ” None
    """
    client_id, client_secret = get_clova_api_keys()
    if not client_id or not client_secret:
        return None

    # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (2000ì)
    if len(text) > 2000:
        text = text[:2000]

    headers = {
        "X-NCP-APIGW-API-KEY-ID": client_id,
        "X-NCP-APIGW-API-KEY": client_secret,
        "Content-Type": "application/x-www-form-urlencoded",
    }

    # ê°ì • ì§€ì› ì—¬ë¶€ í™•ì¸
    speaker_info = CLOVA_SPEAKERS.get(speaker, {})
    supports_emotion = speaker_info.get("emotion", False)

    data = {
        "speaker": speaker,
        "text": text,
        "volume": str(volume),
        "speed": str(speed),
        "pitch": str(pitch),
        "format": "mp3",
    }

    # ê°ì • ì§€ì› ìŠ¤í”¼ì»¤ë§Œ ê°ì • íŒŒë¼ë¯¸í„° ì¶”ê°€
    if supports_emotion and emotion > 0:
        data["emotion"] = str(emotion)
        data["emotion-strength"] = "2"  # ê°ì • ê°•ë„ (1: ì•½í•¨, 2: ë³´í†µ, 3: ê°•í•¨)

    try:
        r = requests.post(
            CLOVA_VOICE_URL,
            headers=headers,
            data=data,
            timeout=30
        )

        if r.status_code == 200:
            return r.content
        else:
            print(f"CLOVA TTS Error: {r.status_code} - {r.text}")
            return None

    except Exception as e:
        print(f"CLOVA TTS API Error: {e}")
        return None


# =====================
# ë‚˜ì´/ì„±ë³„ë³„ TTS ìŒì„± ë§¤í•‘ (OpenAI ë°±ì—…ìš©)
# =====================
# OpenAI TTS ìŒì„±:
# - alloy: ì¤‘ì„±ì , ì Šì€ ëŠë‚Œ
# - echo: ë‚¨ì„±, ì¤‘ì €ìŒ
# - fable: í‘œí˜„ë ¥ ì¢‹ìŒ, ì´ì•¼ê¸°ì²´
# - onyx: ë‚¨ì„±, ê¹Šê³  ê¶Œìœ„ìˆëŠ” ëŠë‚Œ
# - nova: ì—¬ì„±, ë”°ëœ»í•˜ê³  ì¹œê·¼í•¨
# - shimmer: ì—¬ì„±, ë¶€ë“œëŸ½ê³  ì°¨ë¶„í•¨

def get_voice_for_persona(persona: str, escalation_level: int = 0) -> Tuple[str, float]:
    """
    ìŠ¹ê° í˜ë¥´ì†Œë‚˜ì—ì„œ ë‚˜ì´/ì„±ë³„ì„ íŒŒì•…í•˜ì—¬ ì í•©í•œ TTS ìŒì„±ê³¼ ì†ë„ ë°˜í™˜
    ê°ì • ë ˆë²¨ì— ë”°ë¼ ì†ë„ ì¡°ì ˆ (í™”ë‚ ìˆ˜ë¡ ë¹¨ë¼ì§)

    Args:
        persona: ìŠ¹ê° í˜ë¥´ì†Œë‚˜ ë¬¸ìì—´ (ì˜ˆ: "50ëŒ€ ì—¬ì„±, í•´ì™¸ì—¬í–‰ì´ ì²˜ìŒ...")
        escalation_level: ê°ì • ë ˆë²¨ (0: í‰ìƒì‹œ, 1: ì§œì¦, 2: í™”ë‚¨)

    Returns:
        (voice_id, speed) íŠœí”Œ
    """
    # ê°ì •ì— ë”°ë¥¸ ì†ë„ ë°°ìœ¨
    emotion_speed_multiplier = {
        0: 1.0,    # í‰ìƒì‹œ: ë³´í†µ ì†ë„
        1: 1.08,   # ì§œì¦: ì•½ê°„ ë¹ ë¥´ê²Œ
        2: 1.15,   # í™”ë‚¨: ë” ë¹ ë¥´ê²Œ
    }
    speed_mult = emotion_speed_multiplier.get(escalation_level, 1.0)

    # ì„±ë³„ íŒë‹¨
    is_female = any(keyword in persona for keyword in ['ì—¬ì„±', 'ì—„ë§ˆ', 'ì•„ì´ ì—„ë§ˆ', 'í• ë¨¸ë‹ˆ', 'ì—¬ì', 'ë¶€ì¸', 'ì„ì‚°ë¶€', 'ì•„ì¤Œë§ˆ'])
    is_male = any(keyword in persona for keyword in ['ë‚¨ì„±', 'ì•„ë¹ ', 'í• ì•„ë²„ì§€', 'ë‚¨ì', 'ì‚¬ì—…ê°€']) and not is_female

    # ë‚˜ì´ëŒ€ íŒë‹¨
    age_group = "middle"  # ê¸°ë³¸ê°’: ì¤‘ë…„

    if any(keyword in persona for keyword in ['20ëŒ€', 'ì´ì‹­ëŒ€', 'ëŒ€í•™ìƒ', 'ì Šì€']):
        age_group = "young"
    elif any(keyword in persona for keyword in ['30ëŒ€', 'ì‚¼ì‹­ëŒ€', 'ì§ì¥ì¸']):
        age_group = "young_adult"
    elif any(keyword in persona for keyword in ['40ëŒ€', 'ì‚¬ì‹­ëŒ€']):
        age_group = "middle"
    elif any(keyword in persona for keyword in ['50ëŒ€', 'ì˜¤ì‹­ëŒ€']):
        age_group = "middle_aged"
    elif any(keyword in persona for keyword in ['60ëŒ€', 'ìœ¡ì‹­ëŒ€', '70ëŒ€', 'ì¹ ì‹­ëŒ€', 'ì–´ë¥´ì‹ ', 'í• ë¨¸ë‹ˆ', 'í• ì•„ë²„ì§€', 'ë…¸ì¸']):
        age_group = "elderly"

    # íŠ¹ìˆ˜ í˜ë¥´ì†Œë‚˜ ì²´í¬
    if 'ì–´ë¦°ì´' in persona or 'ì•„ë™' in persona:
        return ("alloy", 1.1 * speed_mult)

    if 'ì™¸êµ­ì¸' in persona:
        return ("fable", 1.0 * speed_mult)

    # ì„±ë³„ + ë‚˜ì´ ì¡°í•©ìœ¼ë¡œ ìŒì„± ì„ íƒ
    if is_female:
        if age_group in ["young", "young_adult"]:
            base_speed = 1.05
            voice = "nova"
        elif age_group == "middle":
            # 40ëŒ€ ì•„ì¤Œë§ˆ: nova, ê¸°ë³¸ ë¹ ë¦„
            base_speed = 1.1 if escalation_level > 0 else 1.0
            voice = "nova"
        elif age_group == "middle_aged":
            # 50ëŒ€ ì—¬ì„±: shimmer
            base_speed = 1.0
            voice = "shimmer"
        else:  # elderly
            # 60-70ëŒ€ ì—¬ì„±: shimmer, ëŠë¦¬ê²Œ
            base_speed = 0.92
            voice = "shimmer"
    else:
        # ë‚¨ì„± ë˜ëŠ” ì„±ë³„ ë¶ˆëª…í™•
        if age_group in ["young", "young_adult"]:
            base_speed = 1.05
            voice = "echo"
        elif age_group == "middle":
            # 40ëŒ€ ë‚¨ì„±/ì‚¬ì—…ê°€: echo
            base_speed = 1.0
            voice = "echo"
        elif age_group == "middle_aged":
            # 50ëŒ€ ë‚¨ì„±: onyx
            base_speed = 0.98
            voice = "onyx"
        else:  # elderly
            # 60-70ëŒ€ ë‚¨ì„±: onyx, ëŠë¦¬ê²Œ
            base_speed = 0.9
            voice = "onyx"

    final_speed = min(base_speed * speed_mult, 1.25)  # ìµœëŒ€ 1.25ë°°ì†
    return (voice, final_speed)


def get_openai_api_key() -> str:
    """OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°"""
    return (
        os.environ.get("OPENAI_API_KEY", "")
        or os.environ.get("OPENAI_APIKEY", "")
        or os.environ.get("OPENAI_KEY", "")
    )


def transcribe_audio(audio_bytes: bytes, language: str = "ko") -> Optional[Dict[str, Any]]:
    """
    OpenAI Whisper APIë¡œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

    Args:
        audio_bytes: ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë°ì´í„°
        language: ì–¸ì–´ ì½”ë“œ (ko, en)

    Returns:
        {
            "text": "ì¸ì‹ëœ í…ìŠ¤íŠ¸",
            "duration": 10.5,  # ì´ˆ ë‹¨ìœ„
            "words": [{"word": "ì•ˆë…•", "start": 0.0, "end": 0.5}, ...]
        }
    """
    api_key = get_openai_api_key()
    if not api_key:
        return None

    headers = {
        "Authorization": f"Bearer {api_key}",
    }

    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(suffix=".webm", delete=False) as f:
        f.write(audio_bytes)
        temp_path = f.name

    try:
        with open(temp_path, "rb") as audio_file:
            files = {
                "file": ("audio.webm", audio_file, "audio/webm"),
            }
            data = {
                "model": "whisper-1",
                "language": language,
                "response_format": "verbose_json",
                "timestamp_granularities": ["word"],
            }

            r = requests.post(
                f"{OPENAI_API_URL}/audio/transcriptions",
                headers=headers,
                files=files,
                data=data,
                timeout=60
            )
            r.raise_for_status()
            result = r.json()

            return {
                "text": result.get("text", ""),
                "duration": result.get("duration", 0),
                "words": result.get("words", []),
                "language": result.get("language", language),
            }

    except Exception as e:
        print(f"Whisper API Error: {e}")
        return None

    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        try:
            os.unlink(temp_path)
        except:
            pass


def analyze_voice_quality(
    transcription: Dict[str, Any],
    expected_duration_range: Tuple[int, int] = (60, 90),
) -> Dict[str, Any]:
    """
    ìŒì„± í’ˆì§ˆ ë¶„ì„

    Args:
        transcription: transcribe_audio ê²°ê³¼
        expected_duration_range: ì ì • ë‹µë³€ ì‹œê°„ ë²”ìœ„ (ì´ˆ)

    Returns:
        {
            "speech_rate": {"wpm": 150, "score": 8, "feedback": "ì ì ˆí•œ ì†ë„"},
            "filler_words": {"count": 3, "list": ["ìŒ", "ì–´"], "score": 7, "feedback": "..."},
            "pauses": {"count": 2, "long_pauses": 1, "score": 8, "feedback": "..."},
            "duration": {"seconds": 75, "score": 10, "feedback": "ì ì ˆí•œ ì‹œê°„"},
            "clarity": {"score": 8, "feedback": "..."},
            "total_score": 82,
            "total_feedback": "..."
        }
    """
    text = transcription.get("text", "")
    duration = transcription.get("duration", 0)
    words = transcription.get("words", [])

    result = {
        "speech_rate": {},
        "filler_words": {},
        "pauses": {},
        "duration": {},
        "clarity": {},
        "total_score": 0,
        "total_feedback": "",
    }

    # 1. ë§ ì†ë„ ë¶„ì„ (WPM - Words Per Minute)
    word_count = len(text.split())
    if duration > 0:
        wpm = int((word_count / duration) * 60)
    else:
        wpm = 0

    if 120 <= wpm <= 160:
        rate_score = 10
        rate_feedback = "ì ì ˆí•œ ë§ ì†ë„ì…ë‹ˆë‹¤."
    elif 100 <= wpm < 120 or 160 < wpm <= 180:
        rate_score = 7
        rate_feedback = "ì•½ê°„ ëŠë¦¬ê±°ë‚˜ ë¹ ë¦…ë‹ˆë‹¤." if wpm < 120 else "ì•½ê°„ ë¹ ë¦…ë‹ˆë‹¤."
    elif wpm < 100:
        rate_score = 4
        rate_feedback = "ë„ˆë¬´ ëŠë¦½ë‹ˆë‹¤. ìì‹ ê° ìˆê²Œ ë§í•´ë³´ì„¸ìš”."
    else:
        rate_score = 4
        rate_feedback = "ë„ˆë¬´ ë¹ ë¦…ë‹ˆë‹¤. ì²œì²œíˆ ë˜ë°•ë˜ë°• ë§í•´ë³´ì„¸ìš”."

    result["speech_rate"] = {
        "wpm": wpm,
        "score": rate_score,
        "feedback": rate_feedback,
    }

    # 2. í•„ëŸ¬ ë‹¨ì–´ ë¶„ì„
    filler_patterns = [
        r'\bìŒ+\b', r'\bì–´+\b', r'\bê·¸+\b', r'\bì•„+\b',
        r'\bê·¸ëŸ¬ë‹ˆê¹Œ\b', r'\bê·¸ë˜ì„œ\b', r'\bë­ë„ê¹Œ\b',
        r'\bì•½ê°„\b', r'\bì¢€\b', r'\bì§„ì§œ\b', r'\bë§‰\b',
        r'\bì´ì œ\b', r'\bê·¼ë°\b', r'\bê·¸ëƒ¥\b',
    ]

    filler_count = 0
    filler_list = []
    for pattern in filler_patterns:
        matches = re.findall(pattern, text, re.IGNORECASE)
        if matches:
            filler_count += len(matches)
            filler_list.extend(matches)

    # 1ë¶„ë‹¹ í•„ëŸ¬ ë‹¨ì–´ ìˆ˜ë¡œ ì •ê·œí™”
    if duration > 0:
        filler_per_min = (filler_count / duration) * 60
    else:
        filler_per_min = 0

    if filler_per_min <= 3:
        filler_score = 10
        filler_feedback = "ë¶ˆí•„ìš”í•œ ì¶”ì„ìƒˆê°€ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤."
    elif filler_per_min <= 6:
        filler_score = 7
        filler_feedback = "ì¶”ì„ìƒˆë¥¼ ì¡°ê¸ˆ ì¤„ì´ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤."
    elif filler_per_min <= 10:
        filler_score = 4
        filler_feedback = "ì¶”ì„ìƒˆê°€ ë§ìŠµë‹ˆë‹¤. ì˜ì‹ì ìœ¼ë¡œ ì¤„ì—¬ë³´ì„¸ìš”."
    else:
        filler_score = 2
        filler_feedback = "ì¶”ì„ìƒˆê°€ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ì¹¨ë¬µì„ ë‘ë ¤ì›Œí•˜ì§€ ë§ˆì„¸ìš”."

    result["filler_words"] = {
        "count": filler_count,
        "list": list(set(filler_list))[:5],  # ìƒìœ„ 5ê°œë§Œ
        "score": filler_score,
        "feedback": filler_feedback,
    }

    # 3. ë¬µìŒ/íœ´ì§€ ë¶„ì„
    if words:
        pauses = []
        long_pauses = 0
        for i in range(1, len(words)):
            prev_end = words[i-1].get("end", 0)
            curr_start = words[i].get("start", 0)
            gap = curr_start - prev_end
            if gap > 0.5:
                pauses.append(gap)
                if gap > 2.0:
                    long_pauses += 1

        pause_count = len(pauses)

        if pause_count <= 3 and long_pauses == 0:
            pause_score = 10
            pause_feedback = "ìì—°ìŠ¤ëŸ¬ìš´ íë¦„ì…ë‹ˆë‹¤."
        elif pause_count <= 5 and long_pauses <= 1:
            pause_score = 7
            pause_feedback = "ì „ë°˜ì ìœ¼ë¡œ ê´œì°®ì§€ë§Œ ê¸´ ì¹¨ë¬µì´ ìˆì—ˆìŠµë‹ˆë‹¤."
        else:
            pause_score = 4
            pause_feedback = "ë‹µë³€ì´ ìì£¼ ëŠê¹ë‹ˆë‹¤. ë¯¸ë¦¬ ì •ë¦¬í•´ì„œ ë§í•´ë³´ì„¸ìš”."

        result["pauses"] = {
            "count": pause_count,
            "long_pauses": long_pauses,
            "score": pause_score,
            "feedback": pause_feedback,
        }
    else:
        result["pauses"] = {
            "count": 0,
            "long_pauses": 0,
            "score": 7,
            "feedback": "íœ´ì§€ ë¶„ì„ ë°ì´í„° ì—†ìŒ",
        }

    # 4. ë‹µë³€ ì‹œê°„ ë¶„ì„
    min_duration, max_duration = expected_duration_range
    if min_duration <= duration <= max_duration:
        duration_score = 10
        duration_feedback = f"ì ì ˆí•œ ë‹µë³€ ì‹œê°„ì…ë‹ˆë‹¤. ({int(duration)}ì´ˆ)"
    elif duration < min_duration * 0.5:
        duration_score = 3
        duration_feedback = f"ë‹µë³€ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ({int(duration)}ì´ˆ) êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ ì¶”ê°€í•˜ì„¸ìš”."
    elif duration < min_duration:
        duration_score = 6
        duration_feedback = f"ì¡°ê¸ˆ ë” ìì„¸íˆ ë‹µë³€í•´ë„ ì¢‹ìŠµë‹ˆë‹¤. ({int(duration)}ì´ˆ)"
    elif duration <= max_duration * 1.3:
        duration_score = 6
        duration_feedback = f"ì•½ê°„ ê¹ë‹ˆë‹¤. ({int(duration)}ì´ˆ) í•µì‹¬ë§Œ ì „ë‹¬í•˜ì„¸ìš”."
    else:
        duration_score = 3
        duration_feedback = f"ë‹µë³€ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ({int(duration)}ì´ˆ) ê°„ê²°í•˜ê²Œ ì •ë¦¬í•˜ì„¸ìš”."

    result["duration"] = {
        "seconds": int(duration),
        "score": duration_score,
        "feedback": duration_feedback,
    }

    # 5. ë°œìŒ ëª…í™•ì„± (ê°„ì ‘ ì¸¡ì • - ì¸ì‹ëœ ë‹¨ì–´ ìˆ˜ ê¸°ë°˜)
    if words:
        recognized_ratio = len(words) / max(word_count, 1)
        if recognized_ratio >= 0.9:
            clarity_score = 10
            clarity_feedback = "ë°œìŒì´ ëª…í™•í•©ë‹ˆë‹¤."
        elif recognized_ratio >= 0.7:
            clarity_score = 7
            clarity_feedback = "ë°œìŒì´ ëŒ€ì²´ë¡œ ëª…í™•í•©ë‹ˆë‹¤."
        else:
            clarity_score = 4
            clarity_feedback = "ë°œìŒì„ ë” ë˜ë ·í•˜ê²Œ í•´ì£¼ì„¸ìš”."
    else:
        clarity_score = 7
        clarity_feedback = "ë°œìŒ ë¶„ì„ ë°ì´í„° ì—†ìŒ"

    result["clarity"] = {
        "score": clarity_score,
        "feedback": clarity_feedback,
    }

    # ì´ì  ê³„ì‚° (ê°€ì¤‘ í‰ê· )
    weights = {
        "speech_rate": 0.2,
        "filler_words": 0.25,
        "pauses": 0.15,
        "duration": 0.2,
        "clarity": 0.2,
    }

    total_score = (
        result["speech_rate"]["score"] * weights["speech_rate"] +
        result["filler_words"]["score"] * weights["filler_words"] +
        result["pauses"]["score"] * weights["pauses"] +
        result["duration"]["score"] * weights["duration"] +
        result["clarity"]["score"] * weights["clarity"]
    ) * 10  # 100ì  ë§Œì ìœ¼ë¡œ í™˜ì‚°

    result["total_score"] = int(total_score)

    # ì´í‰
    if total_score >= 80:
        result["total_feedback"] = "ìŒì„± ì „ë‹¬ë ¥ì´ ìš°ìˆ˜í•©ë‹ˆë‹¤. ìì‹ ê° ìˆê²Œ ë©´ì ‘ì— ì„í•˜ì„¸ìš”!"
    elif total_score >= 60:
        result["total_feedback"] = "ê¸°ë³¸ì ì¸ ì „ë‹¬ë ¥ì€ ê°–ì¶”ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ í”¼ë“œë°±ì„ ì°¸ê³ í•´ ê°œì„ í•´ë³´ì„¸ìš”."
    else:
        result["total_feedback"] = "ìŒì„± ì „ë‹¬ë ¥ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤. ê¾¸ì¤€í•œ ì—°ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤."

    return result


# =====================
# ìŒì„± ë¶„ì„ ì ìˆ˜ ê¸°ì¤€ (í•­ê³µì‚¬ ë©´ì ‘ íŠ¹í™”)
# =====================

VOICE_SCORING = {
    "speech_rate": {
        "perfect": (120, 150),      # WPM - ì™„ë²½ ë²”ìœ„
        "acceptable": (100, 170),   # WPM - í—ˆìš© ë²”ìœ„
        "deduct_per_violation": 5   # ë²”ìœ„ ë²—ì–´ë‚˜ë©´ -5ì 
    },
    "filler_words": {
        "perfect": 0,               # í•„ëŸ¬ 0ê°œ
        "acceptable": 3,            # 3ê°œ ì´í•˜
        "deduct_per_extra": 2       # ì´ˆê³¼ 1ê°œë‹¹ -2ì 
    },
    "silence_gaps": {
        "max_allowed": 3,           # 2ì´ˆ ì´ìƒ ì¹¨ë¬µ ìµœëŒ€ 3íšŒ
        "deduct_per_extra": 3       # ì´ˆê³¼ 1íšŒë‹¹ -3ì 
    },
    "response_time": {
        "perfect": (3, 10),         # 3~10ì´ˆ (ë¡¤í”Œë ˆì‰: ì½ê¸°+ìƒê°+ì‘ë‹µ)
        "acceptable": (2, 20),      # 2~20ì´ˆ í—ˆìš©
        "deduct_if_outside": 5      # ë²”ìœ„ ë²—ì–´ë‚˜ë©´ -5ì 
    },
    "pitch_variation": {
        "monotone_threshold": 20,   # Hz ë³€í™”ëŸ‰ 20 ì´í•˜ë©´ ë‹¨ì¡°ë¡œì›€
        "deduct_if_monotone": 5
    },
    "volume_stability": {
        "max_drop_percent": 30,     # ëë¶€ë¶„ ìŒëŸ‰ 30% ì´ìƒ ê°ì†Œ ì‹œ
        "deduct_if_drops": 5
    },
    "service_tone": {
        "greeting_pitch_rise": 10,  # ì²« ì¸ì‚¬ í”¼ì¹˜ ìƒìŠ¹ ìµœì†Œ %
        "ending_softness": True,    # ë¬¸ì¥ ë ë¶€ë“œëŸ¬ì›€
    },
    "composure": {
        "speed_change_threshold": 30,  # ë§ ì†ë„ 30% ì´ìƒ ê¸‰ë³€ ì‹œ
        "filler_spike_threshold": 3,   # êµ¬ê°„ë³„ í•„ëŸ¬ 3ê°œ ì´ìƒ ê¸‰ì¦ ì‹œ
    }
}


# =====================
# ê³ ê¸‰ ìŒì„± ë¶„ì„ (ëª©ì†Œë¦¬ ë–¨ë¦¼, ë§ë íë¦¼, í†¤ ë³€í™” ë“±)
# =====================

def analyze_voice_advanced(audio_bytes: bytes) -> Dict[str, Any]:
    """
    ê³ ê¸‰ ìŒì„± í’ˆì§ˆ ë¶„ì„ - ëª©ì†Œë¦¬ ë–¨ë¦¼, ë§ë íë¦¼, í†¤ ë³€í™” ë“±

    Args:
        audio_bytes: ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë°ì´í„°

    Returns:
        {
            "tremor": {"score": 8, "level": "ì•½í•¨", "feedback": "..."},
            "ending_clarity": {"score": 7, "issue": "ë§ë íë¦¼", "feedback": "..."},
            "pitch_variation": {"score": 8, "type": "ì ì ˆí•¨", "feedback": "..."},
            "energy_consistency": {"score": 7, "feedback": "..."},
            "confidence_score": 75,
            "confidence_feedback": "..."
        }
    """
    result = {
        "tremor": {"score": 7, "level": "ë¶„ì„ë¶ˆê°€", "feedback": "ìŒì„± ë¶„ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."},
        "ending_clarity": {"score": 7, "issue": "ë¶„ì„ë¶ˆê°€", "feedback": ""},
        "pitch_variation": {"score": 7, "type": "ë¶„ì„ë¶ˆê°€", "feedback": ""},
        "energy_consistency": {"score": 7, "feedback": ""},
        "service_tone": {"score": 7, "greeting_bright": False, "ending_soft": False, "feedback": "ë¶„ì„ë¶ˆê°€"},
        "composure": {"score": 7, "speed_stable": True, "filler_stable": True, "feedback": "ë¶„ì„ë¶ˆê°€"},
        "confidence_score": 70,
        "confidence_feedback": "ê¸°ë³¸ ë¶„ì„ë§Œ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.",
    }

    try:
        import numpy as np
        import io
        import wave
        import struct
    except ImportError:
        return result

    # librosa ì‚¬ìš© ì‹œë„ (ê³ ê¸‰ ë¶„ì„)
    try:
        import librosa
        import librosa.display
        HAS_LIBROSA = True
    except ImportError:
        HAS_LIBROSA = False

    # scipy í´ë°±
    try:
        from scipy import signal
        from scipy.io import wavfile
        HAS_SCIPY = True
    except ImportError:
        HAS_SCIPY = False

    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    temp_path = None
    try:
        with tempfile.NamedTemporaryFile(suffix=".webm", delete=False) as f:
            f.write(audio_bytes)
            temp_path = f.name

        if HAS_LIBROSA:
            # librosaë¡œ ê³ ê¸‰ ë¶„ì„
            y, sr = librosa.load(temp_path, sr=None)

            # 1. ëª©ì†Œë¦¬ ë–¨ë¦¼ ë¶„ì„ (Jitter - í”¼ì¹˜ ë³€ë™ì„±)
            try:
                pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
                pitch_values = []
                for t in range(pitches.shape[1]):
                    index = magnitudes[:, t].argmax()
                    pitch = pitches[index, t]
                    if pitch > 0:
                        pitch_values.append(pitch)

                if len(pitch_values) > 10:
                    pitch_array = np.array(pitch_values)
                    # Jitter: ì—°ì† í”¼ì¹˜ ì°¨ì´ì˜ ë³€ë™ì„±
                    pitch_diff = np.abs(np.diff(pitch_array))
                    jitter = np.mean(pitch_diff) / (np.mean(pitch_array) + 1e-6) * 100

                    if jitter < 1.0:
                        tremor_score = 10
                        tremor_level = "ì—†ìŒ"
                        tremor_feedback = "ëª©ì†Œë¦¬ê°€ ë§¤ìš° ì•ˆì •ì ì…ë‹ˆë‹¤. ìì‹ ê°ì´ ëŠê»´ì§‘ë‹ˆë‹¤."
                    elif jitter < 2.0:
                        tremor_score = 8
                        tremor_level = "ì•½í•¨"
                        tremor_feedback = "ëª©ì†Œë¦¬ê°€ ëŒ€ì²´ë¡œ ì•ˆì •ì ì…ë‹ˆë‹¤."
                    elif jitter < 3.5:
                        tremor_score = 5
                        tremor_level = "ë³´í†µ"
                        tremor_feedback = "ì•½ê°„ì˜ ë–¨ë¦¼ì´ ê°ì§€ë©ë‹ˆë‹¤. ê¸´ì¥ì„ í’€ê³  ì²œì²œíˆ ë§í•´ë³´ì„¸ìš”."
                    else:
                        tremor_score = 3
                        tremor_level = "ì‹¬í•¨"
                        tremor_feedback = "ëª©ì†Œë¦¬ ë–¨ë¦¼ì´ ë§ìŠµë‹ˆë‹¤. ì‹¬í˜¸í¡ í›„ ì°¨ë¶„í•˜ê²Œ ë§í•´ë³´ì„¸ìš”."

                    result["tremor"] = {
                        "score": tremor_score,
                        "level": tremor_level,
                        "jitter_percent": round(jitter, 2),
                        "feedback": tremor_feedback,
                    }
            except Exception as e:
                print(f"Tremor analysis error: {e}")

            # 2. ë§ë íë¦¼ ë¶„ì„ (ë¬¸ì¥ ë ì—ë„ˆì§€ í•˜ê°•)
            try:
                # RMS ì—ë„ˆì§€ ê³„ì‚°
                rms = librosa.feature.rms(y=y)[0]

                if len(rms) > 20:
                    # ë§ˆì§€ë§‰ 20% êµ¬ê°„ì˜ ì—ë„ˆì§€
                    last_portion = int(len(rms) * 0.2)
                    first_portion = int(len(rms) * 0.3)

                    avg_start_energy = np.mean(rms[:first_portion])
                    avg_end_energy = np.mean(rms[-last_portion:])

                    # ì—ë„ˆì§€ ë¹„ìœ¨ (ë/ì‹œì‘)
                    energy_ratio = avg_end_energy / (avg_start_energy + 1e-6)

                    if energy_ratio >= 0.7:
                        ending_score = 10
                        ending_issue = "ì—†ìŒ"
                        ending_feedback = "ë§ëê¹Œì§€ ëª…í™•í•˜ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤."
                    elif energy_ratio >= 0.5:
                        ending_score = 7
                        ending_issue = "ì•½ê°„ íë¦¼"
                        ending_feedback = "ë§ ëì´ ì•½ê°„ íë ¤ì§‘ë‹ˆë‹¤. ë¬¸ì¥ ëê¹Œì§€ í˜ì„ ìœ ì§€í•˜ì„¸ìš”."
                    elif energy_ratio >= 0.3:
                        ending_score = 4
                        ending_issue = "íë¦¼"
                        ending_feedback = "ë§ëì´ íë ¤ì ¸ ìì‹ ê° ì—†ì–´ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëê¹Œì§€ ë˜ë ·í•˜ê²Œ!"
                    else:
                        ending_score = 2
                        ending_issue = "ë§¤ìš° íë¦¼"
                        ending_feedback = "ë¬¸ì¥ ëì´ ê±°ì˜ ë“¤ë¦¬ì§€ ì•ŠìŠµë‹ˆë‹¤. ëê¹Œì§€ í™•ì‹¤í•˜ê²Œ ë°œìŒí•˜ì„¸ìš”."

                    result["ending_clarity"] = {
                        "score": ending_score,
                        "issue": ending_issue,
                        "energy_ratio": round(energy_ratio, 2),
                        "feedback": ending_feedback,
                    }
            except Exception as e:
                print(f"Ending clarity analysis error: {e}")

            # 3. í”¼ì¹˜ ë³€í™” ë¶„ì„ (ë‹¨ì¡°ë¡œì›€ vs ìƒë™ê°)
            try:
                if len(pitch_values) > 10:
                    pitch_std = np.std(pitch_values)
                    pitch_mean = np.mean(pitch_values)
                    pitch_cv = (pitch_std / (pitch_mean + 1e-6)) * 100  # ë³€ë™ê³„ìˆ˜

                    if 15 <= pitch_cv <= 35:
                        pitch_score = 10
                        pitch_type = "ìƒë™ê° ìˆìŒ"
                        pitch_feedback = "ì ì ˆí•œ ì–µì–‘ ë³€í™”ë¡œ ë“£ê¸° ì¢‹ìŠµë‹ˆë‹¤."
                    elif 10 <= pitch_cv < 15 or 35 < pitch_cv <= 45:
                        pitch_score = 7
                        pitch_type = "ë³´í†µ"
                        pitch_feedback = "ì–µì–‘ ë³€í™”ê°€ ì¡°ê¸ˆ ë” ìˆìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤." if pitch_cv < 15 else "ì–µì–‘ì´ ì¡°ê¸ˆ ê³¼í•©ë‹ˆë‹¤."
                    elif pitch_cv < 10:
                        pitch_score = 4
                        pitch_type = "ë‹¨ì¡°ë¡œì›€"
                        pitch_feedback = "ì–µì–‘ì´ ë„ˆë¬´ ë‹¨ì¡°ë¡­ìŠµë‹ˆë‹¤. ì¤‘ìš”í•œ ë¶€ë¶„ì€ ê°•ì¡°í•˜ì„¸ìš”."
                    else:
                        pitch_score = 4
                        pitch_type = "ë¶ˆì•ˆì •"
                        pitch_feedback = "ì–µì–‘ ë³€í™”ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ì°¨ë¶„í•˜ê²Œ ë§í•´ë³´ì„¸ìš”."

                    result["pitch_variation"] = {
                        "score": pitch_score,
                        "type": pitch_type,
                        "variation_percent": round(pitch_cv, 1),
                        "feedback": pitch_feedback,
                    }
            except Exception as e:
                print(f"Pitch variation analysis error: {e}")

            # 4. ì—ë„ˆì§€ ì¼ê´€ì„± (ë§ ì¤‘ê°„ì— í˜ ë¹ ì§)
            try:
                if len(rms) > 20:
                    # êµ¬ê°„ë³„ ì—ë„ˆì§€ ë³€í™”
                    segment_size = len(rms) // 5
                    segments = [np.mean(rms[i*segment_size:(i+1)*segment_size]) for i in range(5)]

                    # ì¤‘ê°„ êµ¬ê°„ë“¤ì˜ ì—ë„ˆì§€ê°€ ì¼ì •í•œì§€
                    mid_segments = segments[1:4]
                    mid_std = np.std(mid_segments)
                    mid_mean = np.mean(mid_segments)
                    consistency = 1 - (mid_std / (mid_mean + 1e-6))

                    if consistency >= 0.85:
                        energy_score = 10
                        energy_feedback = "ì¼ì •í•œ í˜ìœ¼ë¡œ ë§í•©ë‹ˆë‹¤."
                    elif consistency >= 0.7:
                        energy_score = 7
                        energy_feedback = "ëŒ€ì²´ë¡œ ì¼ì •í•˜ì§€ë§Œ ì¤‘ê°„ì— ì•½ê°„ í˜ì´ ë¹ ì§€ëŠ” ë¶€ë¶„ì´ ìˆìŠµë‹ˆë‹¤."
                    elif consistency >= 0.5:
                        energy_score = 5
                        energy_feedback = "ë§í•˜ëŠ” ì¤‘ê°„ì— í˜ì´ ë¹ ì§‘ë‹ˆë‹¤. ëê¹Œì§€ ì§‘ì¤‘í•´ì„œ ë§í•˜ì„¸ìš”."
                    else:
                        energy_score = 3
                        energy_feedback = "ì—ë„ˆì§€ ë³€ë™ì´ í½ë‹ˆë‹¤. í˜¸í¡ì„ ê³ ë¥´ê²Œ í•˜ê³  ë§í•˜ì„¸ìš”."

                    result["energy_consistency"] = {
                        "score": energy_score,
                        "consistency": round(consistency, 2),
                        "feedback": energy_feedback,
                    }
            except Exception as e:
                print(f"Energy consistency analysis error: {e}")

            # 5. ì„œë¹„ìŠ¤ í†¤ ë¶„ì„ (ì²« ì¸ì‚¬ ë°ê¸°, ë¬¸ì¥ ë ë¶€ë“œëŸ¬ì›€)
            try:
                if len(pitch_values) > 20:
                    # ì²˜ìŒ 20% êµ¬ê°„ì˜ í”¼ì¹˜ (ì¸ì‚¬ ë¶€ë¶„)
                    first_portion = int(len(pitch_values) * 0.2)
                    mid_portion_start = int(len(pitch_values) * 0.3)
                    mid_portion_end = int(len(pitch_values) * 0.7)

                    first_pitch = np.mean(pitch_values[:first_portion])
                    mid_pitch = np.mean(pitch_values[mid_portion_start:mid_portion_end])

                    # ì²« ì¸ì‚¬ê°€ ë°ì€ê°€? (í”¼ì¹˜ê°€ í‰ê· ë³´ë‹¤ ë†’ìœ¼ë©´ ë°ìŒ)
                    pitch_rise_percent = ((first_pitch - mid_pitch) / (mid_pitch + 1e-6)) * 100
                    greeting_bright = pitch_rise_percent >= VOICE_SCORING["service_tone"]["greeting_pitch_rise"]

                    # ë¬¸ì¥ ë ë¶€ë“œëŸ¬ì›€ (ending_clarityì™€ ì—°ê³„)
                    ending_soft = result["ending_clarity"].get("score", 0) >= 7

                    # ì ìˆ˜ ê³„ì‚°
                    service_score = 5
                    if greeting_bright and ending_soft:
                        service_score = 10
                        service_feedback = "ë°ì€ ì¸ì‚¬ì™€ ë¶€ë“œëŸ¬ìš´ ë§ˆë¬´ë¦¬ê°€ ì¢‹ìŠµë‹ˆë‹¤!"
                    elif greeting_bright:
                        service_score = 8
                        service_feedback = "ì²« ì¸ì‚¬ê°€ ë°ìŠµë‹ˆë‹¤. ë¬¸ì¥ ëë„ ë¶€ë“œëŸ½ê²Œ ë§ˆë¬´ë¦¬í•˜ë©´ ë” ì¢‹ìŠµë‹ˆë‹¤."
                    elif ending_soft:
                        service_score = 7
                        service_feedback = "ë§ˆë¬´ë¦¬ê°€ ë¶€ë“œëŸ½ìŠµë‹ˆë‹¤. ì²« ì¸ì‚¬ë¥¼ ë” ë°ê²Œ í•˜ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤."
                    else:
                        service_score = 4
                        service_feedback = "ì¸ì‚¬ë¥¼ ë” ë°ê²Œ, ë¬¸ì¥ ëì„ ë¶€ë“œëŸ½ê²Œ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”."

                    result["service_tone"] = {
                        "score": service_score,
                        "greeting_bright": greeting_bright,
                        "ending_soft": ending_soft,
                        "pitch_rise_percent": round(pitch_rise_percent, 1),
                        "feedback": service_feedback,
                    }
            except Exception as e:
                print(f"Service tone analysis error: {e}")

            # 6. ì¹¨ì°©í•¨ ë¶„ì„ (ë§ ì†ë„ ê¸‰ë³€, í•„ëŸ¬ ê¸‰ì¦)
            try:
                # êµ¬ê°„ë³„ ë§ ì†ë„ ë¶„ì„ (í”¼ì¹˜ ê°„ê²©ìœ¼ë¡œ ëŒ€ë¦¬ ì¸¡ì •)
                if len(words_data := []) > 0 or len(pitch_values) > 30:
                    # 5êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ ì„œ í”¼ì¹˜ ë°€ë„(= ë§ ë¹ ë¥´ê¸° proxy) ë¶„ì„
                    segment_count = 5
                    segment_len = len(pitch_values) // segment_count

                    segment_densities = []
                    for i in range(segment_count):
                        start = i * segment_len
                        end = (i + 1) * segment_len
                        # ìœ íš¨ í”¼ì¹˜ ë°€ë„
                        valid_count = sum(1 for p in pitch_values[start:end] if p > 0)
                        segment_densities.append(valid_count)

                    # ë§ ì†ë„ ê¸‰ë³€ ì²´í¬
                    if len(segment_densities) > 1:
                        density_changes = []
                        for i in range(1, len(segment_densities)):
                            if segment_densities[i-1] > 0:
                                change = abs(segment_densities[i] - segment_densities[i-1]) / segment_densities[i-1] * 100
                                density_changes.append(change)

                        max_change = max(density_changes) if density_changes else 0
                        speed_stable = max_change < VOICE_SCORING["composure"]["speed_change_threshold"]
                    else:
                        speed_stable = True
                        max_change = 0

                    # í•„ëŸ¬ ê¸‰ì¦ ì²´í¬ëŠ” í…ìŠ¤íŠ¸ ë¶„ì„ì—ì„œ ìˆ˜í–‰ (ì—¬ê¸°ì„  ê¸°ë³¸ê°’)
                    filler_stable = True

                    # ì ìˆ˜ ê³„ì‚°
                    if speed_stable and filler_stable:
                        composure_score = 10
                        composure_feedback = "ì¹¨ì°©í•˜ê²Œ ì¼ì •í•œ ì†ë„ë¡œ ë§í•©ë‹ˆë‹¤."
                    elif speed_stable:
                        composure_score = 7
                        composure_feedback = "ë§ ì†ë„ëŠ” ì•ˆì •ì ì´ì§€ë§Œ ì¶”ì„ìƒˆê°€ ë§ìŠµë‹ˆë‹¤."
                    elif filler_stable:
                        composure_score = 6
                        composure_feedback = "ë§ ì†ë„ê°€ ê¸‰ë³€í•©ë‹ˆë‹¤. ê¸´ì¥ ì‹œ ë” ì²œì²œíˆ ë§í•˜ì„¸ìš”."
                    else:
                        composure_score = 4
                        composure_feedback = "ê¸´ì¥ì´ ëŠê»´ì§‘ë‹ˆë‹¤. ì‹¬í˜¸í¡ í›„ ì²œì²œíˆ ë˜ë°•ë˜ë°• ë§í•˜ì„¸ìš”."

                    result["composure"] = {
                        "score": composure_score,
                        "speed_stable": speed_stable,
                        "filler_stable": filler_stable,
                        "max_speed_change": round(max_change, 1),
                        "feedback": composure_feedback,
                    }
            except Exception as e:
                print(f"Composure analysis error: {e}")

        elif HAS_SCIPY:
            # scipyë¡œ ê¸°ë³¸ ë¶„ì„ (librosa ì—†ì„ ë•Œ)
            try:
                # webmì„ ì§ì ‘ ë¶„ì„í•˜ê¸° ì–´ë ¤ìš°ë¯€ë¡œ ê°„ë‹¨í•œ ë¶„ì„ë§Œ
                result["tremor"]["feedback"] = "ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰ (librosa ì„¤ì¹˜ ì‹œ ì •ë°€ ë¶„ì„ ê°€ëŠ¥)"
                result["ending_clarity"]["feedback"] = "ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰"
                result["pitch_variation"]["feedback"] = "ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰"
                result["energy_consistency"]["feedback"] = "ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰"
            except Exception as e:
                print(f"Scipy analysis error: {e}")

        # 7. ìì‹ ê° ì¢…í•© ì ìˆ˜ (ëª¨ë“  í•­ëª© í¬í•¨)
        scores = [
            result["tremor"].get("score", 7),
            result["ending_clarity"].get("score", 7),
            result["pitch_variation"].get("score", 7),
            result["energy_consistency"].get("score", 7),
            result["service_tone"].get("score", 7),
            result["composure"].get("score", 7),
        ]

        confidence_score = int(np.mean(scores) * 10)

        if confidence_score >= 85:
            confidence_feedback = "ìì‹ ê° ë„˜ì¹˜ëŠ” ìŒì„±ì…ë‹ˆë‹¤! ë©´ì ‘ì—ì„œ ì¢‹ì€ ì¸ìƒì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        elif confidence_score >= 70:
            confidence_feedback = "ê´œì°®ì€ ìˆ˜ì¤€ì…ë‹ˆë‹¤. ì•„ë˜ í”¼ë“œë°±ì„ ì°¸ê³ í•´ ê°œì„ í•˜ë©´ ë” ì¢‹ì•„ì§‘ë‹ˆë‹¤."
        elif confidence_score >= 55:
            confidence_feedback = "ìì‹ ê°ì´ ë¶€ì¡±í•´ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—°ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤."
        else:
            confidence_feedback = "ê¸´ì¥ì´ ë§ì´ ëŠê»´ì§‘ë‹ˆë‹¤. ì¶©ë¶„í•œ ì—°ìŠµê³¼ ì‹¬í˜¸í¡ìœ¼ë¡œ ì•ˆì •ì„ ì°¾ìœ¼ì„¸ìš”."

        result["confidence_score"] = confidence_score
        result["confidence_feedback"] = confidence_feedback

    except Exception as e:
        print(f"Advanced voice analysis error: {e}")

    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if temp_path:
            try:
                os.unlink(temp_path)
            except:
                pass

    return result


def analyze_voice_complete(
    audio_bytes: bytes,
    transcription: Dict[str, Any] = None,
    expected_duration_range: Tuple[int, int] = (10, 60),
    response_times: List[float] = None,
) -> Dict[str, Any]:
    """
    ìŒì„± ì¢…í•© ë¶„ì„ (í…ìŠ¤íŠ¸ ë¶„ì„ + ê³ ê¸‰ ìŒì„± ë¶„ì„ + ì‘ë‹µ ì‹œê°„)

    Args:
        audio_bytes: ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë°ì´í„°
        transcription: transcribe_audio ê²°ê³¼ (ì—†ìœ¼ë©´ ìë™ ìˆ˜í–‰)
        expected_duration_range: ì ì • ë‹µë³€ ì‹œê°„ ë²”ìœ„ (ì´ˆ)
        response_times: ê° ì‘ë‹µë³„ ì†Œìš” ì‹œê°„ ë¦¬ìŠ¤íŠ¸ (ì´ˆ)

    Returns:
        {
            "text_analysis": {...},  # ê¸°ì¡´ analyze_voice_quality ê²°ê³¼
            "voice_analysis": {...},  # ê³ ê¸‰ ìŒì„± ë¶„ì„ ê²°ê³¼
            "response_time_analysis": {...},  # ì‘ë‹µ ì‹œê°„ ë¶„ì„
            "total_score": 75,
            "grade": "B",
            "summary": "...",
            "top_improvements": ["...", "..."]
        }
    """
    # 1. í…ìŠ¤íŠ¸ ë¶„ì„ (STT ê²°ê³¼ ê¸°ë°˜)
    if transcription is None:
        transcription = transcribe_audio(audio_bytes, language="ko")

    if transcription:
        text_analysis = analyze_voice_quality(transcription, expected_duration_range)
    else:
        text_analysis = {
            "speech_rate": {"score": 5, "feedback": "ìŒì„± ì¸ì‹ ì‹¤íŒ¨"},
            "filler_words": {"score": 5, "feedback": "ë¶„ì„ ë¶ˆê°€"},
            "pauses": {"score": 5, "feedback": "ë¶„ì„ ë¶ˆê°€"},
            "duration": {"score": 5, "feedback": "ë¶„ì„ ë¶ˆê°€"},
            "clarity": {"score": 5, "feedback": "ë¶„ì„ ë¶ˆê°€"},
            "total_score": 50,
            "total_feedback": "ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
        }

    # 2. ê³ ê¸‰ ìŒì„± ë¶„ì„
    voice_analysis = analyze_voice_advanced(audio_bytes)

    # 3. ì‘ë‹µ ì‹œê°„ ë¶„ì„
    response_time_analysis = {
        "score": 7,
        "avg_time": 0,
        "feedback": "ì‘ë‹µ ì‹œê°„ ë°ì´í„° ì—†ìŒ",
    }

    if response_times and len(response_times) > 0:
        import numpy as np
        avg_time = np.mean(response_times)
        min_time, max_time = VOICE_SCORING["response_time"]["perfect"]
        acceptable_min, acceptable_max = VOICE_SCORING["response_time"]["acceptable"]

        if min_time <= avg_time <= max_time:
            rt_score = 10
            rt_feedback = f"ì ì ˆí•œ ì‘ë‹µ ì†ë„ì…ë‹ˆë‹¤. (í‰ê·  {avg_time:.1f}ì´ˆ)"
        elif acceptable_min <= avg_time <= acceptable_max:
            rt_score = 7
            if avg_time < min_time:
                rt_feedback = f"ì‘ë‹µì´ ì¡°ê¸ˆ ë¹ ë¦…ë‹ˆë‹¤. (í‰ê·  {avg_time:.1f}ì´ˆ) ì ì‹œ ìƒê° í›„ ë‹µí•˜ì„¸ìš”."
            else:
                rt_feedback = f"ì‘ë‹µì´ ì¡°ê¸ˆ ëŠë¦½ë‹ˆë‹¤. (í‰ê·  {avg_time:.1f}ì´ˆ) ë” ë¹ ë¥´ê²Œ ë°˜ì‘í•˜ì„¸ìš”."
        elif avg_time < acceptable_min:
            rt_score = 4
            rt_feedback = f"ë„ˆë¬´ ì¦‰ë‹µí•©ë‹ˆë‹¤. (í‰ê·  {avg_time:.1f}ì´ˆ) ê²½ì²­ í›„ ë‹µë³€í•˜ì„¸ìš”."
        else:
            rt_score = 4
            rt_feedback = f"ì‘ë‹µì´ ë„ˆë¬´ ëŠë¦½ë‹ˆë‹¤. (í‰ê·  {avg_time:.1f}ì´ˆ) ì§ˆë¬¸ì— ë¹ ë¥´ê²Œ ë°˜ì‘í•˜ì„¸ìš”."

        response_time_analysis = {
            "score": rt_score,
            "avg_time": round(avg_time, 1),
            "times": response_times,
            "feedback": rt_feedback,
        }

    # 4. ì¢…í•© ì ìˆ˜ ê³„ì‚°
    text_score = text_analysis.get("total_score", 50)
    voice_score = voice_analysis.get("confidence_score", 70)
    rt_score = response_time_analysis.get("score", 7)

    # í…ìŠ¤íŠ¸ ë‚´ìš© 50%, ìŒì„± í’ˆì§ˆ 35%, ì‘ë‹µ ì‹œê°„ 15% ê°€ì¤‘ì¹˜
    total_score = int(text_score * 0.50 + voice_score * 0.35 + rt_score * 10 * 0.15)

    # ë“±ê¸‰
    if total_score >= 90:
        grade = "S"
    elif total_score >= 80:
        grade = "A"
    elif total_score >= 70:
        grade = "B"
    elif total_score >= 60:
        grade = "C"
    else:
        grade = "D"

    # 4. ê°œì„  í¬ì¸íŠ¸ ì¶”ì¶œ (ì ìˆ˜ ë‚®ì€ ìˆœ)
    improvement_items = []

    # í…ìŠ¤íŠ¸ ë¶„ì„ í•­ëª©
    for key in ["speech_rate", "filler_words", "pauses", "clarity"]:
        if text_analysis.get(key, {}).get("score", 10) <= 6:
            improvement_items.append({
                "area": key,
                "score": text_analysis[key]["score"],
                "feedback": text_analysis[key].get("feedback", ""),
            })

    # ìŒì„± ë¶„ì„ í•­ëª© (ì„œë¹„ìŠ¤ í†¤, ì¹¨ì°©í•¨ í¬í•¨)
    for key in ["tremor", "ending_clarity", "pitch_variation", "energy_consistency", "service_tone", "composure"]:
        if voice_analysis.get(key, {}).get("score", 10) <= 6:
            improvement_items.append({
                "area": key,
                "score": voice_analysis[key]["score"],
                "feedback": voice_analysis[key].get("feedback", ""),
            })

    # ì‘ë‹µ ì‹œê°„ í•­ëª©
    if response_time_analysis.get("score", 10) <= 6:
        improvement_items.append({
            "area": "response_time",
            "score": response_time_analysis["score"],
            "feedback": response_time_analysis.get("feedback", ""),
        })

    # ì ìˆ˜ ë‚®ì€ ìˆœ ì •ë ¬, ìƒìœ„ 3ê°œ
    improvement_items.sort(key=lambda x: x["score"])
    top_improvements = [item["feedback"] for item in improvement_items[:3] if item["feedback"]]

    # 6. ìš”ì•½
    if total_score >= 80:
        summary = f"ìš°ìˆ˜í•œ ìŒì„± ì „ë‹¬ë ¥ì…ë‹ˆë‹¤! (ë“±ê¸‰: {grade})"
    elif total_score >= 65:
        summary = f"ê´œì°®ì€ ìˆ˜ì¤€ì´ì§€ë§Œ ê°œì„ ì˜ ì—¬ì§€ê°€ ìˆìŠµë‹ˆë‹¤. (ë“±ê¸‰: {grade})"
    else:
        summary = f"ìŒì„± ì „ë‹¬ë ¥ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤. ì•„ë˜ í”¼ë“œë°±ì„ ì°¸ê³ í•˜ì„¸ìš”. (ë“±ê¸‰: {grade})"

    return {
        "text_analysis": text_analysis,
        "voice_analysis": voice_analysis,
        "response_time_analysis": response_time_analysis,
        "total_score": total_score,
        "grade": grade,
        "summary": summary,
        "top_improvements": top_improvements if top_improvements else ["í˜„ì¬ ìˆ˜ì¤€ì„ ìœ ì§€í•˜ì„¸ìš”!"],
    }


def generate_tts_audio(
    text: str,
    voice: str = "nova",  # alloy, echo, fable, onyx, nova, shimmer
    speed: float = 1.0,
    use_clova: bool = True,  # í´ë¡œë°” ìš°ì„  ì‚¬ìš©
    persona: str = "",  # í˜ë¥´ì†Œë‚˜ (í´ë¡œë°”ìš©)
    escalation_level: int = 0,  # ê°ì • ë ˆë²¨ (í´ë¡œë°”ìš©)
) -> Optional[bytes]:
    """
    TTSë¡œ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
    - í´ë¡œë°”ê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ í´ë¡œë°” ì‚¬ìš© (ë” ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´)
    - ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ OpenAI TTS ì‚¬ìš©

    Args:
        text: ë³€í™˜í•  í…ìŠ¤íŠ¸
        voice: OpenAI ìŒì„± ì¢…ë¥˜ (í´ë¡œë°” ë¯¸ì‚¬ìš©ì‹œ)
        speed: OpenAI ì†ë„ (0.25 ~ 4.0)
        use_clova: í´ë¡œë°” ìš°ì„  ì‚¬ìš© ì—¬ë¶€
        persona: ìŠ¹ê° í˜ë¥´ì†Œë‚˜ (í´ë¡œë°”ìš©)
        escalation_level: ê°ì • ë ˆë²¨ (í´ë¡œë°”ìš©)

    Returns:
        MP3 ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë°ì´í„°
    """
    # 1. í´ë¡œë°” ì‹œë„
    if use_clova and is_clova_available():
        if persona:
            speaker, clova_speed, emotion = get_clova_speaker_for_persona(persona, escalation_level)
        else:
            # í˜ë¥´ì†Œë‚˜ ì—†ìœ¼ë©´ ê¸°ë³¸ ì„¤ì •
            speaker = "nara"
            clova_speed = 0
            emotion = CLOVA_EMOTIONS.get("angry", 0) if escalation_level >= 2 else 0

        audio = generate_clova_tts(
            text=text,
            speaker=speaker,
            speed=clova_speed,
            emotion=emotion,
        )
        if audio:
            return audio
        print("CLOVA TTS ì‹¤íŒ¨, OpenAIë¡œ í´ë°±...")

    # 2. OpenAI TTS í´ë°±
    api_key = get_openai_api_key()
    if not api_key:
        return None

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }

    payload = {
        "model": "tts-1-hd",
        "input": text,
        "voice": voice,
        "speed": speed,
    }

    try:
        r = requests.post(
            f"{OPENAI_API_URL}/audio/speech",
            headers=headers,
            json=payload,
            timeout=30
        )
        r.raise_for_status()
        return r.content

    except Exception as e:
        print(f"OpenAI TTS API Error: {e}")
        return None


def generate_tts_for_passenger(
    text: str,
    persona: str,
    escalation_level: int = 0,
) -> Optional[bytes]:
    """
    ìŠ¹ê° ëŒ€ì‚¬ìš© TTS ìƒì„± (í˜ë¥´ì†Œë‚˜/ê°ì • ìë™ ë§¤í•‘)

    Args:
        text: ìŠ¹ê° ëŒ€ì‚¬
        persona: ìŠ¹ê° í˜ë¥´ì†Œë‚˜
        escalation_level: ê°ì • ë ˆë²¨ (0: í‰ìƒì‹œ, 1: ì§œì¦, 2: í™”ë‚¨)

    Returns:
        MP3 ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë°ì´í„°
    """
    # í´ë¡œë°” ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ í´ë¡œë°” ìš°ì„ 
    if is_clova_available():
        speaker, speed, emotion = get_clova_speaker_for_persona(persona, escalation_level)
        audio = generate_clova_tts(
            text=text,
            speaker=speaker,
            speed=speed,
            emotion=emotion,
        )
        if audio:
            return audio

    # OpenAI í´ë°±
    voice, speed = get_voice_for_persona(persona, escalation_level)
    return generate_tts_audio(
        text=text,
        voice=voice,
        speed=speed,
        use_clova=False,  # ì´ë¯¸ í´ë¡œë°” ì‹œë„í–ˆìœ¼ë¯€ë¡œ ìŠ¤í‚µ
    )


def get_loud_audio_component(audio_bytes: bytes, autoplay: bool = True, gain: float = 10.0):
    """
    ë³¼ë¥¨ ì¦í­ëœ ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ (Streamlit components.html ì‚¬ìš©)

    Args:
        audio_bytes: MP3 ì˜¤ë””ì˜¤ ë°”ì´íŠ¸
        autoplay: ìë™ ì¬ìƒ ì—¬ë¶€
        gain: ë³¼ë¥¨ ì¦í­ ë°°ìœ¨ (10.0 = 10ë°°)
    """
    import base64
    import streamlit.components.v1 as components

    audio_b64 = base64.b64encode(audio_bytes).decode()

    html_code = f"""
    <!DOCTYPE html>
    <html>
    <body>
    <button id="playBtn" style="padding: 10px 20px; font-size: 16px; cursor: pointer; background: #4CAF50; color: white; border: none; border-radius: 5px;">
        ğŸ”Š ì¬ìƒ (ë³¼ë¥¨ ì¦í­)
    </button>
    <script>
    var audioCtx = null;
    var isPlaying = false;

    document.getElementById('playBtn').addEventListener('click', async function() {{
        if (isPlaying) return;
        isPlaying = true;
        this.textContent = 'ğŸ”Š ì¬ìƒ ì¤‘...';
        this.style.background = '#888';

        try {{
            if (!audioCtx) {{
                audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            }}
            if (audioCtx.state === 'suspended') {{
                await audioCtx.resume();
            }}

            var base64 = "{audio_b64}";
            var binaryString = atob(base64);
            var len = binaryString.length;
            var bytes = new Uint8Array(len);
            for (var i = 0; i < len; i++) {{
                bytes[i] = binaryString.charCodeAt(i);
            }}

            var audioBuffer = await audioCtx.decodeAudioData(bytes.buffer);
            var source = audioCtx.createBufferSource();
            source.buffer = audioBuffer;

            var gainNode = audioCtx.createGain();
            gainNode.gain.value = {gain};

            source.connect(gainNode);
            gainNode.connect(audioCtx.destination);

            source.onended = function() {{
                isPlaying = false;
                document.getElementById('playBtn').textContent = 'ğŸ”Š ì¬ìƒ (ë³¼ë¥¨ ì¦í­)';
                document.getElementById('playBtn').style.background = '#4CAF50';
            }};

            source.start(0);
        }} catch(e) {{
            console.error('Audio error:', e);
            isPlaying = false;
            this.textContent = 'ğŸ”Š ì¬ìƒ (ë³¼ë¥¨ ì¦í­)';
            this.style.background = '#4CAF50';
        }}
    }});

    {"document.getElementById('playBtn').click();" if autoplay else ""}
    </script>
    </body>
    </html>
    """

    components.html(html_code, height=60)


def get_audio_player_html(audio_bytes: bytes, autoplay: bool = False, volume_boost: float = 2.0) -> str:
    """
    ì˜¤ë””ì˜¤ ì¬ìƒìš© HTML ìƒì„± (ê¸°ë³¸ í”Œë ˆì´ì–´)

    Args:
        audio_bytes: MP3 ì˜¤ë””ì˜¤ ë°”ì´íŠ¸
        autoplay: ìë™ ì¬ìƒ ì—¬ë¶€
        volume_boost: ì‚¬ìš©í•˜ì§€ ì•ŠìŒ

    Returns:
        HTML ë¬¸ìì—´
    """
    import base64

    audio_b64 = base64.b64encode(audio_bytes).decode()
    autoplay_attr = "autoplay" if autoplay else ""

    return f"""<audio {autoplay_attr} controls style="width: 100%;"><source src="data:audio/mp3;base64,{audio_b64}" type="audio/mp3"></audio>"""


def evaluate_answer_content(
    question: str,
    answer_text: str,
    airline: str = "",
    airline_type: str = "LCC",
) -> Dict[str, Any]:
    """
    ë‹µë³€ ë‚´ìš© í‰ê°€ (GPT-4o-mini)

    Args:
        question: ë©´ì ‘ ì§ˆë¬¸
        answer_text: ë‹µë³€ í…ìŠ¤íŠ¸
        airline: í•­ê³µì‚¬ëª…
        airline_type: FSC/LCC

    Returns:
        {
            "content_score": 35,  # /40
            "structure_score": 25,  # /30
            "delivery_score": 12,  # /15
            "relevance_score": 13,  # /15
            "total_score": 85,
            "star_check": {...},
            "strengths": [...],
            "improvements": [...],
            "sample_answer": "..."
        }
    """
    api_key = get_openai_api_key()
    if not api_key:
        return {"error": "API í‚¤ ì—†ìŒ"}

    system_prompt = f"""ë‹¹ì‹ ì€ ì—„ê²©í•œ í•­ê³µì‚¬ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ì§€ì› í•­ê³µì‚¬: {airline} ({airline_type})

ë‹µë³€ì„ ê°ê´€ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”. í›„í•œ ì ìˆ˜ë¥¼ ì£¼ì§€ ë§ˆì„¸ìš”.

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "content_score": 0-40,
    "content_feedback": "ë‚´ìš© í”¼ë“œë°±",
    "structure_score": 0-30,
    "structure_feedback": "êµ¬ì¡° í”¼ë“œë°±",
    "delivery_score": 0-15,
    "delivery_feedback": "ì „ë‹¬ë ¥ í”¼ë“œë°±",
    "relevance_score": 0-15,
    "relevance_feedback": "ì§ˆë¬¸ ê´€ë ¨ì„± í”¼ë“œë°±",
    "star_check": {{
        "situation": true/false,
        "task": true/false,
        "action": true/false,
        "result": true/false
    }},
    "strengths": ["ê°•ì 1", "ê°•ì 2"],
    "improvements": ["ê°œì„ ì 1", "ê°œì„ ì 2", "ê°œì„ ì 3"],
    "sample_answer": "ëª¨ë²” ë‹µë³€ ì˜ˆì‹œ (3-4ë¬¸ì¥)"
}}

ì ìˆ˜ ê¸°ì¤€:
- content (40ì ): êµ¬ì²´ì  ê²½í—˜, ìˆ«ì/ì‚¬ë¡€, ì§„ì •ì„±
- structure (30ì ): ë‘ê´„ì‹, STAR êµ¬ì¡°, ë…¼ë¦¬ íë¦„
- delivery (15ì ): ìì‹ ê° ìˆëŠ” í‘œí˜„, "ê²ƒ ê°™ìŠµë‹ˆë‹¤" ê³¼ë‹¤ ì‚¬ìš© ê°ì 
- relevance (15ì ): ì§ˆë¬¸ ì˜ë„ íŒŒì•…, í•µì‹¬ ë‹µë³€"""

    user_prompt = f"""ì§ˆë¬¸: {question}

ë‹µë³€: {answer_text}

ìœ„ ë‹µë³€ì„ í‰ê°€í•´ì£¼ì„¸ìš”."""

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }

    payload = {
        "model": "gpt-4o-mini",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "temperature": 0.3,
        "response_format": {"type": "json_object"},
    }

    try:
        r = requests.post(
            f"{OPENAI_API_URL}/chat/completions",
            headers=headers,
            json=payload,
            timeout=30
        )
        r.raise_for_status()
        result = r.json()
        content = result.get("choices", [{}])[0].get("message", {}).get("content", "")
        parsed = json.loads(content)

        # ì´ì  ê³„ì‚°
        total = (
            parsed.get("content_score", 0) +
            parsed.get("structure_score", 0) +
            parsed.get("delivery_score", 0) +
            parsed.get("relevance_score", 0)
        )
        parsed["total_score"] = total

        return parsed

    except Exception as e:
        return {"error": str(e)}


# =====================================================
# Google Cloud TTS ì—°ë™ (Neural2 - ê³ í’ˆì§ˆ í•œêµ­ì–´)
# =====================================================

# Google Cloud TTS API ì„¤ì •
GOOGLE_TTS_URL = "https://texttospeech.googleapis.com/v1/text:synthesize"

# Google Cloud TTS í•œêµ­ì–´ ìŒì„± ëª©ë¡ (Neural2 = ìµœê³  í’ˆì§ˆ)
GOOGLE_TTS_VOICES = {
    # Neural2 (ìµœê³  í’ˆì§ˆ) - ì¶”ì²œ
    "ko-KR-Neural2-A": {"name": "ì—¬ì„± A (Neural2)", "gender": "female", "quality": "neural2", "desc": "ìì—°ìŠ¤ëŸ¬ìš´ ì—¬ì„± ìŒì„±"},
    "ko-KR-Neural2-B": {"name": "ì—¬ì„± B (Neural2)", "gender": "female", "quality": "neural2", "desc": "ë¶€ë“œëŸ¬ìš´ ì—¬ì„± ìŒì„±"},
    "ko-KR-Neural2-C": {"name": "ë‚¨ì„± A (Neural2)", "gender": "male", "quality": "neural2", "desc": "ìì—°ìŠ¤ëŸ¬ìš´ ë‚¨ì„± ìŒì„±"},

    # Wavenet (ê³ í’ˆì§ˆ)
    "ko-KR-Wavenet-A": {"name": "ì—¬ì„± A (Wavenet)", "gender": "female", "quality": "wavenet", "desc": "ì—¬ì„± ìŒì„±"},
    "ko-KR-Wavenet-B": {"name": "ì—¬ì„± B (Wavenet)", "gender": "female", "quality": "wavenet", "desc": "ì—¬ì„± ìŒì„±"},
    "ko-KR-Wavenet-C": {"name": "ë‚¨ì„± A (Wavenet)", "gender": "male", "quality": "wavenet", "desc": "ë‚¨ì„± ìŒì„±"},
    "ko-KR-Wavenet-D": {"name": "ë‚¨ì„± B (Wavenet)", "gender": "male", "quality": "wavenet", "desc": "ë‚¨ì„± ìŒì„±"},

    # Standard (ë¬´ë£Œ í• ë‹¹ëŸ‰ ë§ìŒ)
    "ko-KR-Standard-A": {"name": "ì—¬ì„± (Standard)", "gender": "female", "quality": "standard", "desc": "ê¸°ë³¸ ì—¬ì„± ìŒì„±"},
    "ko-KR-Standard-B": {"name": "ì—¬ì„± (Standard)", "gender": "female", "quality": "standard", "desc": "ê¸°ë³¸ ì—¬ì„± ìŒì„±"},
    "ko-KR-Standard-C": {"name": "ë‚¨ì„± (Standard)", "gender": "male", "quality": "standard", "desc": "ê¸°ë³¸ ë‚¨ì„± ìŒì„±"},
    "ko-KR-Standard-D": {"name": "ë‚¨ì„± (Standard)", "gender": "male", "quality": "standard", "desc": "ê¸°ë³¸ ë‚¨ì„± ìŒì„±"},
}


def get_google_api_key() -> str:
    """Google Cloud API í‚¤ ê°€ì ¸ì˜¤ê¸°"""
    return (
        os.environ.get("GOOGLE_TTS_API_KEY", "")
        or os.environ.get("GOOGLE_CLOUD_API_KEY", "")
        or os.environ.get("GOOGLE_API_KEY", "")
    )


def is_google_tts_available() -> bool:
    """Google Cloud TTS ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
    return bool(get_google_api_key())


def get_google_voice_for_persona(persona: str, escalation_level: int = 0) -> Tuple[str, float, float]:
    """
    í˜ë¥´ì†Œë‚˜ì— ë§ëŠ” Google TTS ìŒì„± ì„ íƒ

    Args:
        persona: ìŠ¹ê° í˜ë¥´ì†Œë‚˜
        escalation_level: ê°ì • ë ˆë²¨ (0: í‰ìƒì‹œ, 1: ì§œì¦, 2: í™”ë‚¨)

    Returns:
        (voice_name, speaking_rate, pitch) íŠœí”Œ
    """
    # ì„±ë³„ íŒë‹¨
    is_female = any(kw in persona for kw in ['ì—¬ì„±', 'ì—„ë§ˆ', 'í• ë¨¸ë‹ˆ', 'ì—¬ì', 'ë¶€ì¸', 'ì„ì‚°ë¶€', 'ì•„ì¤Œë§ˆ'])

    # ê¸°ë³¸ ìŒì„± ì„ íƒ (Neural2 = ìµœê³  í’ˆì§ˆ)
    if is_female:
        voice = "ko-KR-Neural2-A"
    else:
        voice = "ko-KR-Neural2-C"

    # ê°ì •ì— ë”°ë¥¸ ì†ë„/í”¼ì¹˜ ì¡°ì ˆ
    if escalation_level == 0:
        speaking_rate = 1.0
        pitch = 0.0
    elif escalation_level == 1:
        speaking_rate = 1.1  # ì•½ê°„ ë¹ ë¥´ê²Œ
        pitch = 1.0  # ì•½ê°„ ë†’ê²Œ
    else:  # í™”ë‚¨
        speaking_rate = 1.2  # ë” ë¹ ë¥´ê²Œ
        pitch = 2.0  # ë” ë†’ê²Œ

    return (voice, speaking_rate, pitch)


def generate_google_tts(
    text: str,
    voice_name: str = "ko-KR-Neural2-A",
    speaking_rate: float = 1.0,
    pitch: float = 0.0,
    volume_gain_db: float = 0.0,
) -> Optional[bytes]:
    """
    Google Cloud TTS APIë¡œ ìŒì„± ìƒì„±

    Args:
        text: ë³€í™˜í•  í…ìŠ¤íŠ¸
        voice_name: ìŒì„± ì´ë¦„ (ko-KR-Neural2-A ë“±)
        speaking_rate: ë§í•˜ê¸° ì†ë„ (0.25 ~ 4.0, ê¸°ë³¸ 1.0)
        pitch: í”¼ì¹˜ (-20.0 ~ 20.0, ê¸°ë³¸ 0.0)
        volume_gain_db: ë³¼ë¥¨ (-96.0 ~ 16.0, ê¸°ë³¸ 0.0)

    Returns:
        MP3 ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë˜ëŠ” None
    """
    api_key = get_google_api_key()
    if not api_key:
        print("[Google TTS] API í‚¤ ì—†ìŒ")
        return None

    # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (5000ë°”ì´íŠ¸)
    if len(text.encode('utf-8')) > 5000:
        text = text[:1500]  # ëŒ€ëµì ì¸ ì œí•œ

    # API ìš”ì²­ URL (API í‚¤ ë°©ì‹)
    url = f"{GOOGLE_TTS_URL}?key={api_key}"

    headers = {
        "Content-Type": "application/json; charset=utf-8",
    }

    payload = {
        "input": {
            "text": text
        },
        "voice": {
            "languageCode": "ko-KR",
            "name": voice_name,
        },
        "audioConfig": {
            "audioEncoding": "MP3",
            "speakingRate": speaking_rate,
            "pitch": pitch,
            "volumeGainDb": volume_gain_db,
        }
    }

    try:
        r = requests.post(url, headers=headers, json=payload, timeout=30)

        if r.status_code == 200:
            result = r.json()
            audio_content = result.get("audioContent", "")
            if audio_content:
                import base64
                audio_bytes = base64.b64decode(audio_content)
                print(f"[Google TTS] ì„±ê³µ - {voice_name}, {len(audio_bytes)} bytes")
                return audio_bytes
            else:
                print("[Google TTS] ì˜¤ë””ì˜¤ ì»¨í…ì¸  ì—†ìŒ")
                return None
        else:
            print(f"[Google TTS] ì˜¤ë¥˜: {r.status_code} - {r.text[:200]}")
            return None

    except Exception as e:
        print(f"[Google TTS] ì˜ˆì™¸: {e}")
        return None


def generate_tts_for_passenger_v2(
    text: str,
    persona: str,
    escalation_level: int = 0,
    tts_provider: str = "auto",  # "auto", "google", "clova", "openai"
) -> Optional[bytes]:
    """
    ìŠ¹ê° ëŒ€ì‚¬ìš© TTS ìƒì„± (v2 - Google TTS ì§€ì›)

    Args:
        text: ìŠ¹ê° ëŒ€ì‚¬
        persona: ìŠ¹ê° í˜ë¥´ì†Œë‚˜
        escalation_level: ê°ì • ë ˆë²¨ (0: í‰ìƒì‹œ, 1: ì§œì¦, 2: í™”ë‚¨)
        tts_provider: TTS ì œê³µì ì„ íƒ

    Returns:
        MP3 ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë°ì´í„°
    """
    # 1. Google TTS ì‹œë„ (auto ë˜ëŠ” google ì„ íƒ ì‹œ)
    if tts_provider in ["auto", "google"] and is_google_tts_available():
        voice, rate, pitch = get_google_voice_for_persona(persona, escalation_level)
        audio = generate_google_tts(
            text=text,
            voice_name=voice,
            speaking_rate=rate,
            pitch=pitch,
        )
        if audio:
            return audio
        if tts_provider == "google":
            print("[TTS] Google TTS ì‹¤íŒ¨")
            return None

    # 2. CLOVA ì‹œë„ (auto ë˜ëŠ” clova ì„ íƒ ì‹œ)
    if tts_provider in ["auto", "clova"] and is_clova_available():
        speaker, speed, emotion = get_clova_speaker_for_persona(persona, escalation_level)
        audio = generate_clova_tts(
            text=text,
            speaker=speaker,
            speed=speed,
            emotion=emotion,
        )
        if audio:
            return audio
        if tts_provider == "clova":
            print("[TTS] CLOVA TTS ì‹¤íŒ¨")
            return None

    # 3. OpenAI í´ë°±
    voice, speed = get_voice_for_persona(persona, escalation_level)
    return generate_tts_audio(
        text=text,
        voice=voice,
        speed=speed,
        use_clova=False,
    )


# =====================================================
# Edge TTS ì—°ë™ (Microsoft Edge ë¸Œë¼ìš°ì € TTS - ë¬´ë£Œ/ë¬´ì œí•œ)
# =====================================================

# Edge TTS í•œêµ­ì–´ ìŒì„± ëª©ë¡
EDGE_TTS_VOICES = {
    # ì—¬ì„± ìŒì„±
    "ko-KR-SunHiNeural": {"name": "ì„ í¬", "gender": "female", "age": "adult", "desc": "ë°ê³  ì¹œê·¼í•œ ì—¬ì„± ìŒì„±"},
    "ko-KR-YuJinNeural": {"name": "ìœ ì§„", "gender": "female", "age": "young", "desc": "ì Šê³  í™œê¸°ì°¬ ì—¬ì„± ìŒì„±"},

    # ë‚¨ì„± ìŒì„±
    "ko-KR-InJoonNeural": {"name": "ì¸ì¤€", "gender": "male", "age": "adult", "desc": "ì°¨ë¶„í•œ ë‚¨ì„± ìŒì„±"},
    "ko-KR-HyunsuNeural": {"name": "í˜„ìˆ˜", "gender": "male", "age": "adult", "desc": "ì‹ ë¢°ê° ìˆëŠ” ë‚¨ì„± ìŒì„±"},
    "ko-KR-GookMinNeural": {"name": "êµ­ë¯¼", "gender": "male", "age": "adult", "desc": "í‘œì¤€ ë‚¨ì„± ìŒì„±"},
}


def is_edge_tts_available() -> bool:
    """Edge TTS ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ (í•­ìƒ True - API í‚¤ ë¶ˆí•„ìš”)"""
    try:
        import edge_tts
        return True
    except ImportError:
        return False


def get_edge_voice_for_persona(persona: str, escalation_level: int = 0) -> Tuple[str, str, str]:
    """
    í˜ë¥´ì†Œë‚˜ì— ë§ëŠ” Edge TTS ìŒì„± ì„ íƒ

    Args:
        persona: ìŠ¹ê° í˜ë¥´ì†Œë‚˜
        escalation_level: ê°ì • ë ˆë²¨ (0: í‰ìƒì‹œ, 1: ì§œì¦, 2: í™”ë‚¨)

    Returns:
        (voice_name, rate, pitch) íŠœí”Œ (rate/pitchëŠ” ë¬¸ìì—´: "+10%", "-5Hz" ë“±)
    """
    # ì„±ë³„ íŒë‹¨
    is_female = any(kw in persona for kw in ['ì—¬ì„±', 'ì—„ë§ˆ', 'í• ë¨¸ë‹ˆ', 'ì—¬ì', 'ë¶€ì¸', 'ì„ì‚°ë¶€', 'ì•„ì¤Œë§ˆ'])
    is_male = any(kw in persona for kw in ['ë‚¨ì„±', 'ì•„ë¹ ', 'í• ì•„ë²„ì§€', 'ë‚¨ì', 'ì‚¬ì—…ê°€']) and not is_female

    # ë‚˜ì´ëŒ€ íŒë‹¨
    if any(kw in persona for kw in ['20ëŒ€', 'ëŒ€í•™ìƒ', 'ì Šì€']):
        age = "young"
    else:
        age = "adult"

    # ìŒì„± ì„ íƒ
    if is_female:
        if age == "young":
            voice = "ko-KR-YuJinNeural"  # ì Šì€ ì—¬ì„±
        else:
            voice = "ko-KR-SunHiNeural"  # ì„±ì¸ ì—¬ì„±
    else:
        voice = "ko-KR-InJoonNeural"  # ë‚¨ì„±

    # ê°ì •ì— ë”°ë¥¸ ì†ë„/í”¼ì¹˜ ì¡°ì ˆ
    if escalation_level == 0:
        rate = "+0%"
        pitch = "+0Hz"
    elif escalation_level == 1:
        rate = "+10%"  # ì•½ê°„ ë¹ ë¥´ê²Œ
        pitch = "+5Hz"  # ì•½ê°„ ë†’ê²Œ
    else:  # í™”ë‚¨
        rate = "+20%"  # ë” ë¹ ë¥´ê²Œ
        pitch = "+10Hz"  # ë” ë†’ê²Œ

    return (voice, rate, pitch)


def generate_edge_tts(
    text: str,
    voice: str = "ko-KR-SunHiNeural",
    rate: str = "+0%",
    pitch: str = "+0Hz",
) -> Optional[bytes]:
    """
    Edge TTSë¡œ ìŒì„± ìƒì„± (ë¬´ë£Œ/ë¬´ì œí•œ)

    Args:
        text: ë³€í™˜í•  í…ìŠ¤íŠ¸
        voice: ìŒì„± ì´ë¦„
        rate: ë§í•˜ê¸° ì†ë„ (ì˜ˆ: "+10%", "-5%")
        pitch: í”¼ì¹˜ (ì˜ˆ: "+5Hz", "-10Hz")

    Returns:
        MP3 ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë˜ëŠ” None
    """
    try:
        import edge_tts
        import asyncio

        async def _generate():
            communicate = edge_tts.Communicate(text, voice, rate=rate, pitch=pitch)
            audio_data = b""
            async for chunk in communicate.stream():
                if chunk["type"] == "audio":
                    audio_data += chunk["data"]
            return audio_data

        # ì´ë²¤íŠ¸ ë£¨í”„ ì²˜ë¦¬ (Streamlit í™˜ê²½ ê³ ë ¤)
        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            loop = None

        if loop and loop.is_running():
            # ì´ë¯¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ì‹¤í–‰ ì¤‘ì¸ ê²½ìš° (Streamlit)
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(asyncio.run, _generate())
                audio_bytes = future.result(timeout=30)
        else:
            # ìƒˆ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„±
            audio_bytes = asyncio.run(_generate())

        if audio_bytes:
            print(f"[Edge TTS] ì„±ê³µ - {voice}, {len(audio_bytes)} bytes")
            return audio_bytes
        else:
            print("[Edge TTS] ì˜¤ë””ì˜¤ ë°ì´í„° ì—†ìŒ")
            return None

    except ImportError:
        print("[Edge TTS] edge-tts íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install edge-tts")
        return None
    except Exception as e:
        print(f"[Edge TTS] ì˜ˆì™¸: {e}")
        return None


def generate_tts_for_passenger_v3(
    text: str,
    persona: str,
    escalation_level: int = 0,
    tts_provider: str = "edge",  # "edge", "clova", "openai", "auto"
) -> Optional[bytes]:
    """
    ìŠ¹ê° ëŒ€ì‚¬ìš© TTS ìƒì„± (v3 - Edge TTS ìš°ì„ )

    Args:
        text: ìŠ¹ê° ëŒ€ì‚¬
        persona: ìŠ¹ê° í˜ë¥´ì†Œë‚˜
        escalation_level: ê°ì • ë ˆë²¨ (0: í‰ìƒì‹œ, 1: ì§œì¦, 2: í™”ë‚¨)
        tts_provider: TTS ì œê³µì ì„ íƒ (ê¸°ë³¸: edge)

    Returns:
        MP3 ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë°ì´í„°
    """
    # 1. Edge TTS ì‹œë„ (ë¬´ë£Œ, ìš°ì„  ì‚¬ìš©)
    if tts_provider in ["auto", "edge"] and is_edge_tts_available():
        voice, rate, pitch = get_edge_voice_for_persona(persona, escalation_level)
        audio = generate_edge_tts(
            text=text,
            voice=voice,
            rate=rate,
            pitch=pitch,
        )
        if audio:
            return audio
        if tts_provider == "edge":
            print("[TTS] Edge TTS ì‹¤íŒ¨")
            # í´ë°± ì—†ì´ None ë°˜í™˜í•˜ì§€ ì•Šê³  ë‹¤ìŒìœ¼ë¡œ ì§„í–‰

    # 2. CLOVA ì‹œë„
    if tts_provider in ["auto", "clova"] and is_clova_available():
        speaker, speed, emotion = get_clova_speaker_for_persona(persona, escalation_level)
        audio = generate_clova_tts(
            text=text,
            speaker=speaker,
            speed=speed,
            emotion=emotion,
        )
        if audio:
            return audio
        if tts_provider == "clova":
            print("[TTS] CLOVA TTS ì‹¤íŒ¨")
            return None

    # 3. OpenAI í´ë°±
    voice, speed = get_voice_for_persona(persona, escalation_level)
    return generate_tts_audio(
        text=text,
        voice=voice,
        speed=speed,
        use_clova=False,
    )


# =====================================================
# TTS í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
# =====================================================
def test_edge_tts():
    """Edge TTS í…ŒìŠ¤íŠ¸"""
    test_text = "ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ Edge TTSì…ë‹ˆë‹¤. ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ìŒì„±ì„ ë¬´ë£Œë¡œ ë“¤ë ¤ë“œë¦½ë‹ˆë‹¤."

    print("=== Edge TTS í…ŒìŠ¤íŠ¸ ===")
    print(f"Edge TTS ì‚¬ìš© ê°€ëŠ¥: {is_edge_tts_available()}")

    if not is_edge_tts_available():
        print("edge-tts íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”: pip install edge-tts")
        return

    # ê° ìŒì„± í…ŒìŠ¤íŠ¸
    for voice_id, voice_info in EDGE_TTS_VOICES.items():
        print(f"\ní…ŒìŠ¤íŠ¸ ìŒì„±: {voice_info['name']} ({voice_id})")
        audio = generate_edge_tts(test_text, voice=voice_id)
        if audio:
            filename = f"test_{voice_id}.mp3"
            with open(filename, "wb") as f:
                f.write(audio)
            print(f"ì €ì¥ ì™„ë£Œ: {filename} ({len(audio)} bytes)")
        else:
            print("ì‹¤íŒ¨")


def test_google_tts():
    """Google TTS í…ŒìŠ¤íŠ¸"""
    test_text = "ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” êµ¬ê¸€ í´ë¼ìš°ë“œ TTSì…ë‹ˆë‹¤. ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ìŒì„±ì„ ë“¤ë ¤ë“œë¦½ë‹ˆë‹¤."

    print("=== Google TTS í…ŒìŠ¤íŠ¸ ===")
    print(f"API í‚¤ ì„¤ì •: {is_google_tts_available()}")

    if not is_google_tts_available():
        print("Google API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("í™˜ê²½ë³€ìˆ˜ GOOGLE_TTS_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        return

    # Neural2 í…ŒìŠ¤íŠ¸
    for voice in ["ko-KR-Neural2-A", "ko-KR-Neural2-C"]:
        print(f"\ní…ŒìŠ¤íŠ¸ ìŒì„±: {voice}")
        audio = generate_google_tts(test_text, voice_name=voice)
        if audio:
            filename = f"test_{voice}.mp3"
            with open(filename, "wb") as f:
                f.write(audio)
            print(f"ì €ì¥ ì™„ë£Œ: {filename}")
        else:
            print("ì‹¤íŒ¨")


if __name__ == "__main__":
    test_edge_tts()
